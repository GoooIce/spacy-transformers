# Stubs for torch (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from torch._C import *
from .functional import *
from ._tensor_str import set_printoptions as set_printoptions
from .random import get_rng_state as get_rng_state, initial_seed as initial_seed, manual_seed as manual_seed, set_rng_state as set_rng_state
from .serialization import load as load, save as save
from .storage import _StorageBase
from .tensor import Tensor as Tensor
from torch.autograd import enable_grad as enable_grad, no_grad as no_grad, set_grad_enabled as set_grad_enabled
from typing import Any

def typename(o: Any): ...
def is_tensor(obj: Any): ...
def is_storage(obj: Any): ...
def set_default_tensor_type(t: Any) -> None: ...

class DoubleStorage(_C.DoubleStorageBase, _StorageBase): ...
class FloatStorage(_C.FloatStorageBase, _StorageBase): ...
class HalfStorage(_C.HalfStorageBase, _StorageBase): ...
class LongStorage(_C.LongStorageBase, _StorageBase): ...
class IntStorage(_C.IntStorageBase, _StorageBase): ...
class ShortStorage(_C.ShortStorageBase, _StorageBase): ...
class CharStorage(_C.CharStorageBase, _StorageBase): ...
class ByteStorage(_C.ByteStorageBase, _StorageBase): ...
class BoolStorage(_C.BoolStorageBase, _StorageBase): ...

# Names in __all__ with no definition:
#   AVG
#   AggregationType
#   Argument
#   ArgumentSpec
#   Block
#   BoolType
#   ByteTensor
#   CharTensor
#   Code
#   CompilationUnit
#   CompleteArgumentSpec
#   DictType
#   DoubleTensor
#   ExecutionPlanState
#   ExtraFilesMap
#   FatalError
#   FileCheck
#   FloatTensor
#   FloatType
#   Function
#   FunctionSchema
#   Future
#   Generator
#   Gradient
#   Graph
#   GraphExecutorState
#   IODescriptor
#   IntTensor
#   IntType
#   JITException
#   ListType
#   LockingLogger
#   LongTensor
#   Node
#   NoopLogger
#   NumberType
#   OptionalType
#   PyTorchFileReader
#   PyTorchFileWriter
#   SUM
#   ScriptMethod
#   ScriptModule
#   ShortTensor
#   Size
#   StringType
#   TensorType
#   TracingState
#   TupleType
#   Type
#   Use
#   Value
#   chunk
#   cpp
#   default_generator
#   device
#   dtype
#   finfo
#   fork
#   get_default_dtype
#   get_num_threads
#   has_cuda
#   has_cudnn
#   has_lapack
#   has_mkl
#   has_mkldnn
#   has_openmp
#   iinfo
#   import_ir_module
#   import_ir_module_from_buffer
#   is_anomaly_enabled
#   is_grad_enabled
#   layout
#   matmul
#   merge_type_from_type_comment
#   parse_ir
#   parse_type_comment
#   rand
#   randn
#   set_anomaly_enabled
#   set_flush_denormal
#   set_num_threads
#   split
#   stack
#   wait
