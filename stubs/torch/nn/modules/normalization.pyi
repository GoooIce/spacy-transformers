# Stubs for torch.nn.modules.normalization (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from ..._jit_internal import weak_module, weak_script_method
from .module import Module
from typing import Any

class LocalResponseNorm(Module):
    __constants__: Any = ...
    size: Any = ...
    alpha: Any = ...
    beta: Any = ...
    k: Any = ...
    def __init__(self, size: Any, alpha: float = ..., beta: float = ..., k: float = ...) -> None: ...
    def forward(self, input: Any): ...
    def extra_repr(self): ...

class CrossMapLRN2d(Module):
    size: Any = ...
    alpha: Any = ...
    beta: Any = ...
    k: Any = ...
    def __init__(self, size: Any, alpha: float = ..., beta: float = ..., k: int = ...) -> None: ...
    def forward(self, input: Any): ...
    def extra_repr(self): ...

class LayerNorm(Module):
    __constants__: Any = ...
    normalized_shape: Any = ...
    eps: Any = ...
    elementwise_affine: Any = ...
    weight: Any = ...
    bias: Any = ...
    def __init__(self, normalized_shape: Any, eps: float = ..., elementwise_affine: bool = ...) -> None: ...
    def reset_parameters(self) -> None: ...
    def forward(self, input: Any): ...
    def extra_repr(self): ...

class GroupNorm(Module):
    __constants__: Any = ...
    num_groups: Any = ...
    num_channels: Any = ...
    eps: Any = ...
    affine: Any = ...
    weight: Any = ...
    bias: Any = ...
    def __init__(self, num_groups: Any, num_channels: Any, eps: float = ..., affine: bool = ...) -> None: ...
    def reset_parameters(self) -> None: ...
    def forward(self, input: Any): ...
    def extra_repr(self): ...
