# Stubs for torch.nn.modules.sparse (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from .module import Module
from typing import Any, Optional

class Embedding(Module):
    __constants__: Any = ...
    num_embeddings: Any = ...
    embedding_dim: Any = ...
    padding_idx: Any = ...
    max_norm: Any = ...
    norm_type: Any = ...
    scale_grad_by_freq: Any = ...
    weight: Any = ...
    sparse: Any = ...
    def __init__(self, num_embeddings: Any, embedding_dim: Any, padding_idx: Optional[Any] = ..., max_norm: Optional[Any] = ..., norm_type: float = ..., scale_grad_by_freq: bool = ..., sparse: bool = ..., _weight: Optional[Any] = ...) -> None: ...
    def reset_parameters(self) -> None: ...
    def forward(self, input: Any): ...
    def extra_repr(self): ...
    @classmethod
    def from_pretrained(cls, embeddings: Any, freeze: bool = ..., padding_idx: Optional[Any] = ..., max_norm: Optional[Any] = ..., norm_type: float = ..., scale_grad_by_freq: bool = ..., sparse: bool = ...): ...

class EmbeddingBag(Module):
    __constants__: Any = ...
    num_embeddings: Any = ...
    embedding_dim: Any = ...
    max_norm: Any = ...
    norm_type: Any = ...
    scale_grad_by_freq: Any = ...
    weight: Any = ...
    mode: Any = ...
    sparse: Any = ...
    def __init__(self, num_embeddings: Any, embedding_dim: Any, max_norm: Optional[Any] = ..., norm_type: float = ..., scale_grad_by_freq: bool = ..., mode: str = ..., sparse: bool = ..., _weight: Optional[Any] = ...) -> None: ...
    def reset_parameters(self) -> None: ...
    def forward(self, input: Tensor, offsets: Optional[Tensor]=..., per_sample_weights: Optional[Tensor]=...) -> Tensor: ...
    def extra_repr(self): ...
    @classmethod
    def from_pretrained(cls, embeddings: Any, freeze: bool = ..., max_norm: Optional[Any] = ..., norm_type: float = ..., scale_grad_by_freq: bool = ..., mode: str = ..., sparse: bool = ...): ...
