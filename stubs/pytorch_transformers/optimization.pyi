# Stubs for pytorch_transformers.optimization (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from torch.optim import Optimizer
from torch.optim.lr_scheduler import LambdaLR
from typing import Any, Optional

logger: Any

class ConstantLRSchedule(LambdaLR):
    def __init__(self, optimizer: Any, last_epoch: int = ...) -> None: ...

class WarmupConstantSchedule(LambdaLR):
    def __init__(self, optimizer: Any, warmup_steps: Any, last_epoch: int = ...) -> None: ...

class WarmupLinearSchedule(LambdaLR):
    def __init__(self, optimizer: Any, warmup_steps: Any, t_total: Any, last_epoch: int = ...) -> None: ...

class WarmupCosineSchedule(LambdaLR):
    warn_t_total: bool = ...
    def __init__(self, optimizer: Any, warmup_steps: Any, t_total: Any, cycles: float = ..., last_epoch: int = ...) -> None: ...

class WarmupCosineWithHardRestartsSchedule(LambdaLR):
    def __init__(self, optimizer: Any, warmup_steps: Any, t_total: Any, cycles: float = ..., last_epoch: int = ...) -> None: ...

class AdamW(Optimizer):
    def __init__(self, params: Any, lr: float = ..., betas: Any = ..., eps: float = ..., weight_decay: float = ..., correct_bias: bool = ...) -> None: ...
    def step(self, closure: Optional[Any] = ...): ...
