# Stubs for thinc.extra.datasets (Python 3)
#
# NOTE: This dynamically typed stub was automatically generated by stubgen.

from ..compat import basestring
from ..neural.util import partition
from ._vendorized.keras_data_utils import get_file
from typing import Any, Optional

unicode = str
GITHUB: str
ANCORA_1_4_ZIP: Any
EWTB_1_4_ZIP: Any
SNLI_URL: str
QUORA_QUESTIONS_URL: str
IMDB_URL: str

def ancora_pos_tags(encode_words: bool = ...): ...
def ewtb_pos_tags(encode_tags: bool = ..., encode_words: bool = ...): ...
def ud_pos_tags(train_loc: Any, dev_loc: Any, encode_tags: bool = ..., encode_words: bool = ...): ...
def imdb(loc: Optional[Any] = ..., limit: int = ...): ...
def read_wikiner(file_: Any, tagmap: Optional[Any] = ...): ...
def read_imdb(data_dir: Any, limit: int = ...): ...
def read_conll(loc: Any) -> None: ...
def read_csv(csv_loc: Any, label_col: int = ..., text_col: int = ...) -> None: ...
def mnist(): ...
def reuters(): ...
def quora_questions(loc: Optional[Any] = ...): ...

THREE_LABELS: Any
TWO_LABELS: Any

def snli(loc: Optional[Any] = ..., ternary: bool = ...): ...
def stack_exchange(loc: Optional[Any] = ...): ...
def read_snli(loc: Any, label_scheme: Any): ...
def get_word_index(path: str = ...): ...
